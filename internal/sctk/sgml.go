// Copyright (2022 -- present) Shahruk Hossain <shahruk10@gmail.com>
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//		 http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
// ==============================================================================

// Package sctk wraps SCTK tools and provides a simpler interface for generating
// reports and scoring ASR hypotheses submitted in a variety of formats against
// reference transcripts.
package sctk

import (
	"bufio"
	"fmt"
	"os"
	"strconv"
	"strings"

	"github.com/sirupsen/logrus"
	"golang.org/x/net/html"

	"github.com/shahruk10/go-sctk/internal/fileutils"
	"github.com/shahruk10/go-sctk/internal/textutils"
)

const (
	tagSystem         = "system"     // <SYSTEM>
	tagSpeaker        = "speaker"    // <SPEAKER>
	tagPath           = "path"       // <PATH>
	attrTitle         = "title"      // <SYSTEM title="hyp" ... >
	attrID            = "id"         // <SPEAKER id="spk001" ... > or <PATH id="spk001-002" ...>
	attrWordCount     = "word_cnt"   // <PATH word_cnt="10" ...>
	attrSequence      = "sequence"   // <PATH sequence="0" ...>
	attrCaseSensitive = "case_sense" // <PATH case_sense="1" ...>
	wordListDelimiter = ':'          // Delimiter between tuples of (label, ref word, hyp word)
	wordDelimiter     = ','          // Delimiter in tuples of (label, ref word, hyp word)
)

// AlignedHypothesis contains the aligned sentences between reference and a
// hypothesis, indexed by speaker and sentence IDs.
type AlignedHypothesis struct {
	SystemName string                      `json:"system_name"`
	Speakers   map[string]SpeakerSentences `json:"speakers"`
}

// SpeakerSentences contain all the sentences of speaker indexed by sentence ID.
type SpeakerSentences map[string]*AlignedSentence

// An AlignedSentence contains the aligned words between reference and
// hypothesis for a given sentence.
type AlignedSentence struct {
	SystemName string
	SpeakerID  string
	SentenceID string        `json:"sentence_id"`
	Sequence   int           `json:"sequence"`
	WordCount  int           `json:"word_count"`
	Words      []AlignedWord `json:"words"`
}

// AlignedWord contains the reference word and corresponding word in the
// hypothesis (if aligned). It also contains a label field which indicates the
// type of alignment - "correct", "substitution", "insertion", or "deletion".
type AlignedWord struct {
	Label string `json:"eval_label"`
	Ref   string `json:"ref"`
	Hyp   string `json:"hyp"`
}

func WriteAlignment(outPath string, aligned *AlignedHypothesis, format TableFormat) error {
	f, err := os.Create(outPath)
	if err != nil {
		return fmt.Errorf("failed to create output sgml file: %w", err)
	}

	defer fileutils.CloseFileOrLog(f)

	w := bufio.NewWriter(f)
	w.WriteString(aligned.ToTable(format))

	return w.Flush()
}

// ReadAlignmentSgml reads and parses the sgml file generated by sclite,
// containing aligned reference and hypothesis sentences. Errors are logged, and
// if there are none, the data is returned as a valid *AlignedHypothesis,
// otherwise nil.
func ReadAlignmentSgml(sgmlPath string) (*AlignedHypothesis, error) {
	sgmlData, err := os.ReadFile(sgmlPath)
	if err != nil {
		return nil, fmt.Errorf("failed to read sgml file: %w", err)
	}

	tokenizer := html.NewTokenizer(strings.NewReader(string(sgmlData)))

	aligned := AlignedHypothesis{
		Speakers: make(map[string]SpeakerSentences),
	}

	maxTokens := 1000000 //nolint: gomnd // a reasonable limit
	hadErrors := false
	currentSpk := ""

	for i := 0; i < maxTokens; i++ {
		tt := tokenizer.Next()

		switch tt {
		// Done parsing.
		case html.ErrorToken:
			if hadErrors {
				return nil, fmt.Errorf("encountered errors when parsing sgml file, check logs")
			}

			return &aligned, nil

		// Start of new tag.
		case html.StartTagToken:
			t := tokenizer.Token()

			switch {
			case t.Data == tagSystem:
				for _, a := range t.Attr {
					if a.Key == attrTitle {
						aligned.SystemName = a.Val
						break
					}
				}

			case t.Data == tagSpeaker:
				currentSpk = ""
				for _, a := range t.Attr {
					if a.Key == attrID {
						currentSpk = a.Val
						break
					}
				}

				if currentSpk != "" {
					aligned.Speakers[currentSpk] = make(SpeakerSentences)
				}

			case t.Data == tagPath:
				if currentSpk == "" {
					hadErrors = true
					logrus.WithFields(logrus.Fields{
						"speaker": currentSpk,
						"tag":     t.String(),
					}).Error("skipping <PATH> entry in sgml file because speaker ID is empty")

					break
				}

				sent, err := parsePathTag(tokenizer, t, currentSpk)
				if err != nil {
					hadErrors = true
					break // Error is logged in parsePathTag.
				}

				sent.SystemName = aligned.SystemName
				aligned.Speakers[currentSpk][sent.SentenceID] = sent
			}
		}
	}

	return nil, fmt.Errorf("failed to parse sgml file, max token limit exceeded (%d)", maxTokens)
}

// parsePathTag parses the data in and between <PATH> tags in the sgml files
// generated by sclite, containing aligned reference and hypothesis words.
func parsePathTag(tokenizer *html.Tokenizer, t html.Token, speakerID string) (*AlignedSentence, error) {
	var (
		err  error
		sent AlignedSentence
	)

	sent.SpeakerID = speakerID

	// Parsing attributes of the <PATH> tag.
	for _, a := range t.Attr {
		switch {
		case a.Key == attrID:
			sent.SentenceID = a.Val

		case a.Key == attrWordCount:
			sent.WordCount, err = strconv.Atoi(a.Val)
			if err != nil {
				logrus.WithFields(logrus.Fields{
					"speaker":    speakerID,
					"sentence":   sent.SentenceID,
					"word_count": a.Key,
					"error":      err,
				}).Error("failed to convert 'word count' attribute to number")

				return nil, fmt.Errorf("failed to parse sgml file, check logs")
			}

		case a.Key == attrSequence:
			sent.Sequence, err = strconv.Atoi(a.Val)
			if err != nil {
				logrus.WithFields(logrus.Fields{
					"speaker":  speakerID,
					"sentence": sent.SentenceID,
					"sequence": a.Key,
					"error":    err,
				}).Error("failed to convert sentence 'sequence' attribute to number")

				return nil, fmt.Errorf("failed to parse sgml file, check logs")
			}
		}
	}

	if sent.SentenceID == "" {
		logrus.WithFields(logrus.Fields{
			"speaker":    speakerID,
			"sentence":   sent.SentenceID,
			"word_count": sent.WordCount,
		}).Error("sentence ID in sgml is empty")

		return nil, fmt.Errorf("failed to parse sgml file, check logs")
	}

	if sent.WordCount == 0 {
		logrus.WithFields(logrus.Fields{
			"speaker":    speakerID,
			"sentence":   sent.SentenceID,
			"word_count": sent.WordCount,
		}).Warn("word count in sgml is empty")

		return &sent, nil
	}

	// Allocating word slice.
	sent.Words = make([]AlignedWord, 0, sent.WordCount)

	// Getting inner text which contains word list.
	if tt := tokenizer.Next(); tt != html.TextToken {
		logrus.WithFields(logrus.Fields{
			"speaker":    speakerID,
			"sentence":   sent.SentenceID,
			"word_count": sent.WordCount,
		}).Error(" premature EOF when parsing <PATH> tag")

		return nil, fmt.Errorf("failed to parse sgml file, check logs")
	}

	// Splitting word list into tuples of (label, ref word, hyp word).
	listStr := strings.TrimSpace(tokenizer.Token().Data)

	wordList := textutils.FieldsWithQuoted(listStr, wordListDelimiter)
	if len(wordList) != sent.WordCount {
		logrus.WithFields(logrus.Fields{
			"speaker":    speakerID,
			"sentence":   sent.SentenceID,
			"word_count": sent.WordCount,
			"got_words":  len(wordList),
		}).Error("unexpected number of aligned words in aligned sentence")

		return nil, fmt.Errorf("failed to parse sgml file, check logs")
	}

	// Parsing each tuple of (label, ref word, hyp word)
	for i, w := range wordList {
		parts := textutils.FieldsWithQuoted(w, wordDelimiter)

		if len(parts) != 3 {
			logrus.WithFields(logrus.Fields{
				"speaker":       speakerID,
				"sentence":      sent.SentenceID,
				"aligned_index": i,
				"aligned_word":  w,
				"got_parts":     len(parts),
				"want_parts":    3,
			}).Errorf("unexpected number of fields in aligned word")

			return nil, fmt.Errorf("failed to parse sgml file, check logs")
		}

		aw := AlignedWord{
			Label: parts[0],
			Ref:   parts[1],
			Hyp:   parts[2],
		}

		sent.Words = append(sent.Words, aw)
	}

	return &sent, nil
}
